import os
import subprocess
import datetime
import mlx_whisper
import ollama
import sys
import shutil
import re
import json

# ==================== ç”¨æˆ·é…ç½®åŒºåŸŸ ====================
# Obsidian æ”¶ä»¶ç®±è·¯å¾„
OBSIDIAN_VAULT_PATH = "/Users/xnc/vault/Inbox"

# éŸ³é¢‘é™„ä»¶å­˜æ”¾æ–‡ä»¶å¤¹
ASSETS_FOLDER_NAME = "assets"

# æ¨¡å‹é…ç½® (åŒæ¨¡å‹æ¶æ„)
# 1. åˆ†ææ¨¡å‹ï¼šè´Ÿè´£æ‘˜è¦ã€è§‚ç‚¹ã€æ·±åº¦è¯„ä¼° (å»ºè®®ç”¨æ›´èªæ˜çš„æ¨¡å‹ï¼Œå¦‚ qwen2.5:14b, gemini-3-flash)
MODEL_ANALYSIS = "qwen3:8b"

# 2. ç¿»è¯‘æ¨¡å‹ï¼šè´Ÿè´£å…¨æ–‡ç¿»è¯‘ (å»ºè®®ç”¨é€Ÿåº¦å¿«çš„æ¨¡å‹ï¼Œå¦‚ qwen2.5:7b, llama3)
MODEL_TRANSLATION = "qwen3:8b"

# Whisper æ¨¡å‹
WHISPER_MODEL = "mlx-community/whisper-large-v3-turbo"

# ç¿»è¯‘åˆ†å—å¤§å°
INTERNAL_PROCESS_CHUNK = 1500
# ====================================================

def sanitize_filename(name):
    name = re.sub(r'[\\/*?:"<>|]', "", name)
    name = name.replace("\n", "").replace("\r", "").strip()
    return name[:80]

def get_video_info(url):
    print("æ­£åœ¨è·å–è§†é¢‘æ ‡é¢˜...")
    try:
        cmd = [
            "yt-dlp", "--get-title",
            "--cookies-from-browser", "chrome",
            "--no-warnings", url
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        title = result.stdout.strip()
        if not title: raise ValueError("æ ‡é¢˜ä¸ºç©º")
        return sanitize_filename(title)
    except Exception as e:
        print(f"æ ‡é¢˜è·å–å¤±è´¥: {e}")
        return f"ç´ æ_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"

def check_is_duplicate(target_filename):
    file_path = os.path.join(OBSIDIAN_VAULT_PATH, f"{target_filename}.md")
    if os.path.exists(file_path):
        print(f"è·³è¿‡: ç¬”è®°å·²å­˜åœ¨ã€‚")
        return True
    return False

def download_audio(url, temp_filename):
    print(f"[1/4] æ­£åœ¨ä¸‹è½½éŸ³é¢‘...")
    output_template = f"{temp_filename}.%(ext)s"
    cmd = [
        "yt-dlp", "-x", "--audio-format", "m4a",
        "--cookies-from-browser", "chrome",
        "-o", output_template, "--no-playlist", "--newline", url
    ]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
        for file in os.listdir("."):
            if file.startswith(temp_filename) and file.endswith(".m4a"):
                return file
        return None
    except subprocess.CalledProcessError as e:
        print(f"\nä¸‹è½½å‡ºé”™: {e.stderr.decode()}")
        return None

def clean_hallucinations(text):
    """
    ğŸ§¹ æ¸…æ´— Whisper çš„å¤è¯»æœºå¹»è§‰ (ä¾‹å¦‚: feel feel feel...)
    åŸç†ï¼šä½¿ç”¨æ­£åˆ™åŒ¹é…é‡å¤å‡ºç° 5 æ¬¡ä»¥ä¸Šçš„å•è¯æˆ–çŸ­è¯­
    """
    if not text: return text

    # 1. æ¸…æ´—å•è¯é‡å¤ (ä¾‹å¦‚: feel feel feel)
    # \b(\w+)(?:\s+\1\b){4,} -> åŒ¹é…ä¸€ä¸ªå•è¯ï¼Œåé¢è·Ÿç€ 4 æ¬¡ä»¥ä¸Šç›¸åŒçš„å•è¯
    text = re.sub(r'\b(\w+)(?:\s+\1\b){4,}', r'\1', text, flags=re.IGNORECASE)

    # 2. æ¸…æ´—çŸ­è¯­é‡å¤ (ä¾‹å¦‚: and easiest and easiest)
    # åŒ¹é… 2-10 ä¸ªå­—ç¬¦é•¿åº¦çš„çŸ­è¯­ï¼Œé‡å¤ 4 æ¬¡ä»¥ä¸Š
    text = re.sub(r'\b(.{2,20})(?:\s+\1\b){4,}', r'\1', text, flags=re.IGNORECASE)

    # 3. æ¸…æ´—å¸¸è§çš„ Whisper å¹»è§‰è¯ (å¦‚æœä½ å‘ç°è¿˜æœ‰å…¶ä»–çš„ï¼Œå¯ä»¥åŠ åœ¨è¿™é‡Œ)
    # æœ‰äº›ç‰ˆæœ¬çš„ Whisper ä¼šç–¯ç‹‚è¾“å‡º "Thank you." æˆ– "Bye."
    # è¿™é‡Œæ˜¯ä¸€ä¸ªä¿å®ˆçš„æ¸…æ´—ï¼Œåªå»æ‰æœ«å°¾è¿ç»­çš„ Thank you
    text = re.sub(r'(Thank you\.?(\s*)){2,}', 'Thank you.', text, flags=re.IGNORECASE)

    return text.strip()

def transcribe_audio(audio_file):
    """Whisper è½¬å½• + è‡ªåŠ¨æ¸…æ´—"""
    print("\nğŸ™ï¸ [2/4] æ­£åœ¨è½¬å½• (MLXåŠ é€Ÿä¸­)...")
    result = mlx_whisper.transcribe(
        audio_file,
        path_or_hf_repo=WHISPER_MODEL,
        verbose=True
    )

    # === æ–°å¢ï¼šç«‹å³æ¸…æ´—å¹»è§‰ ===
    raw_text = result['text']
    cleaned_text = clean_hallucinations(raw_text)

    # å¦‚æœæ¸…æ´—æ‰äº†å¤§é‡å­—ç¬¦ï¼Œæ‰“å°æç¤º
    if len(raw_text) - len(cleaned_text) > 50:
        print(f"   ğŸ§¹ å·²è‡ªåŠ¨æ¸…é™¤ Whisper å¹»è§‰æ–‡æœ¬ ({len(raw_text) - len(cleaned_text)} å­—ç¬¦)")

    # æ›´æ–° result ä¸­çš„ text
    result['text'] = cleaned_text
    return result

def format_original_text(whisper_result):
    segments = whisper_result.get('segments', [])
    if not segments: return whisper_result['text']
    return "\n".join([seg.get('text', '').strip() for seg in segments])

def generate_intelligence_analysis(full_text):
    """
    ã€V5.4 ç¨³å¥è°ƒè¯•ç‰ˆã€‘ä¿®å¤å˜é‡ä½œç”¨åŸŸ + 32kä¸Šä¸‹æ–‡ + æš´åŠ›JSONæ¸…æ´—
    """
    print(f"\nğŸ§  [3/4] æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ (æ¨¡å‹: {MODEL_ANALYSIS})...")

    # === å˜é‡åˆå§‹åŒ– (ä¿®å¤ Pyright æŠ¥é”™) ===
    # å¿…é¡»åœ¨ try ä¹‹å‰å®šä¹‰ï¼Œå¦åˆ™å¦‚æœ try ç¬¬ä¸€è¡Œå°±æŒ‚äº†ï¼Œexcept é‡Œæ‰“å°ä¼šå†æ¬¡æŠ¥é”™
    full_response_content = ""

    # === 1. åŠ¨æ€è®¡ç®—éœ€è¦çš„ä¸Šä¸‹æ–‡ ===
    # è‹±æ–‡å•è¯æ•° * 1.5 â‰ˆ Tokenæ•°ã€‚ä½ çš„æ–‡æœ¬çº¦ 3800 è¯ â‰ˆ 5700 Tokensã€‚
    # æˆ‘ä»¬è®¾ç½® 32000 (32k) ç»°ç»°æœ‰ä½™ï¼Œèƒ½å®¹çº³ 2 å°æ—¶çš„è§†é¢‘å­—å¹•ã€‚
    current_context_size = 32000

    # === 2. ç®€åŒ–çš„ Prompt ===
    # å¯¹äº 8B æ¨¡å‹ï¼ŒPrompt è¶Šåƒä»£ç è¶Šå¥½ã€‚ä¸è¦ç”¨å¤ªå¤æ‚çš„è‡ªç„¶è¯­è¨€ã€‚
    prompt = f"""
    [Role]
    Professional Strategic Analyst.

    [Task]
    Analyze the provided text.
    Output the result in strict JSON format.
    Language: Simplified Chinese (ç®€ä½“ä¸­æ–‡).

    [JSON Structure]
    {{
        "tags": ["tag1", "tag2"],
        "summary": "Full summary of the content (300 words+)",
        "key_points": ["point1", "point2", "point3"],
        "assessment": {{
            "authenticity": "Evaluation of factuality",
            "effectiveness": "Evaluation of logic/method",
            "timeliness": "Is the info up-to-date?",
            "alternatives": "Alternative viewpoints or solutions"
        }}
    }}

    [Input Text]
    {full_text[:30000]}
    """

    try:
        print(f"   -> æ­£åœ¨æ€è€ƒä¸­ (Context: {current_context_size} tokens)...")

        stream = ollama.chat(
            model=MODEL_ANALYSIS,
            messages=[{'role': 'user', 'content': prompt}],
            # å¼ºåˆ¶ JSON æ¨¡å¼
            format='json',
            options={
                "temperature": 0.1,      # æåº¦ç†æ€§
                "num_ctx": current_context_size, # ã€å…³é”®ã€‘æ‰©å¤§å†…å­˜ï¼Œé˜²æ­¢æˆªæ–­
                "num_predict": 2500,     # å…è®¸è¾“å‡ºè¾ƒé•¿çš„å›ç­”
                "repeat_penalty": 1.1    # é˜²æ­¢å¤è¯»æœº
            },
            stream=True
        )

        for chunk in stream:
            part = chunk['message']['content']
            print(part, end="", flush=True)
            full_response_content += part

        print("\n\n   -> ç”Ÿæˆå®Œæ¯•ï¼Œæ­£åœ¨è§£æ...")

        # === 3. æš´åŠ›æ¸…æ´—ä¸è§£æ ===
        # æœ‰æ—¶å€™æ¨¡å‹è¿˜æ˜¯ä¼šè¾“å‡º ```json ... ``` å“ªæ€•æˆ‘ä»¬å¼€äº† format='json'

        # æ­¥éª¤ A: å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(full_response_content)
        except json.JSONDecodeError:
            # æ­¥éª¤ B: å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™æå–æœ€å¤–å±‚å¤§æ‹¬å·
            print("   -> æ ‡å‡†è§£æå¤±è´¥ï¼Œå°è¯•æš´åŠ›æå–...")
            match = re.search(r"(\{.*\})", full_response_content, re.DOTALL)
            if match:
                json_str = match.group(1)
                # å†æ¬¡æ¸…æ´—ï¼šæœ‰æ—¶ JSON é‡Œçš„æ¢è¡Œç¬¦ä¼šå¯¼è‡´é”™è¯¯
                # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„æ¸…ç†ï¼ˆè§†æƒ…å†µè€Œå®šï¼‰
                return json.loads(json_str)
            else:
                raise ValueError("æœªæ‰¾åˆ°ä»»ä½• {} ç»“æ„")

    except Exception as e:
        print(f"\nâŒ åˆ†æå‘ç”Ÿé”™è¯¯: {e}")

        # === è°ƒè¯•ä¿¡æ¯çš„å…³é”®ä¿®å¤ ===
        print("\nğŸ” === [è°ƒè¯•] æ¨¡å‹åŸå§‹è¾“å‡º (Raw Output) ===")
        print("â†“" * 30)
        # è¿™é‡Œç°åœ¨ç»å¯¹å®‰å…¨äº†ï¼Œå› ä¸º full_response_content åœ¨æœ€ä¸Šé¢å®šä¹‰äº†
        print(full_response_content if full_response_content else "(æ— å†…å®¹/è¿æ¥è¶…æ—¶)")
        print("â†‘" * 30)
        print("ğŸ’¡ è¯·æˆªå›¾ä»¥ä¸Šä¿¡æ¯ä»¥ä¾¿æ’æŸ¥é—®é¢˜ã€‚\n")

        # è¿”å›å…œåº•æ•°æ®ï¼Œç¡®ä¿åç»­æµç¨‹ä¸ä¸­æ–­
        return {
            "tags": ["åˆ†æå¤±è´¥"],
            "summary": f"æ™ºèƒ½åˆ†ææœªèƒ½å®Œæˆã€‚é”™è¯¯ä¿¡æ¯: {str(e)}",
            "key_points": [],
            "assessment": {
                "authenticity": "N/A", "effectiveness": "N/A", "timeliness": "N/A", "alternatives": "N/A"
            }
        }

def translate_full_text_loop(full_text):
    """
    ã€V5.5 ä¿®å¤ç‰ˆã€‘å¢åŠ é˜²å¡æ­»æœºåˆ¶ (Time-out protection)
    """
    # 1. åŠ¨æ€è°ƒæ•´åˆ†å—å¤§å° (å»ºè®®ç¨å¾®å°ä¸€ç‚¹ï¼Œ1500å­—ç¬¦ä¸€æ®µæ¯”è¾ƒç¨³)
    CHUNK_SIZE = 1500

    print(f"\nğŸŒ [4/4] æ­£åœ¨å…¨æ–‡ç¿»è¯‘ (ä½¿ç”¨æ¨¡å‹: {MODEL_TRANSLATION})...")
    print(f"   -> æ€»å­—ç¬¦æ•°: {len(full_text)} | åˆ†å—å¤§å°: {CHUNK_SIZE}")

    chunks = [full_text[i:i+CHUNK_SIZE] for i in range(0, len(full_text), CHUNK_SIZE)]
    total_chunks = len(chunks)
    translated_parts = []

    for i, chunk in enumerate(chunks):
        # æ‰“å°å½“å‰è¿›åº¦ï¼Œflush=True ç¡®ä¿ç«‹å³æ˜¾ç¤º
        print(f"   -> ç¿»è¯‘è¿›åº¦: {i+1}/{total_chunks} ... ", end="", flush=True)

        prompt = f"""
        Translate the following text into Simplified Chinese (ç®€ä½“ä¸­æ–‡).
        Keep the format. Do not add explanations.

        Text:
        {chunk}
        """

        try:
            # === æ ¸å¿ƒä¿®å¤: æ·»åŠ  options é™åˆ¶ ===
            # è¿™èƒ½é˜²æ­¢æ¨¡å‹é™·å…¥æ— é™å¾ªç¯
            response = ollama.chat(
                model=MODEL_TRANSLATION,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    "temperature": 0.3,    # ä½æ¸©ï¼Œä¿è¯ç¿»è¯‘å‡†ç¡®ä¸èƒ¡ç¼–
                    "num_ctx": 4096,       # ç¿»è¯‘ä¸éœ€è¦å¤ªå¤§ä¸Šä¸‹æ–‡ï¼Œ4kè¶³å¤Ÿ
                    "num_predict": 2048,   # ã€å…³é”®ã€‘å¼ºåˆ¶æ­¢æŸï¼é˜²æ­¢æ— é™ç”Ÿæˆ
                }
            )

            content = response['message']['content']
            translated_parts.append(content)
            print("âœ…") # æ‰“å°å¯¹å‹¾è¡¨ç¤ºè¿™ä¸€å—å®Œæˆäº†

        except Exception as e:
            print(f"âŒ (è·³è¿‡: {str(e)})")
            translated_parts.append(f"\n[è¯¥ç‰‡æ®µç¿»è¯‘å¤±è´¥]\n")

    return "\n\n".join(translated_parts)

def move_audio_to_vault(local_audio_file, target_name):
    assets_dir = os.path.join(OBSIDIAN_VAULT_PATH, ASSETS_FOLDER_NAME)
    os.makedirs(assets_dir, exist_ok=True)
    final_name = f"{target_name}.m4a"
    dest_path = os.path.join(assets_dir, final_name)
    if os.path.exists(dest_path): os.remove(dest_path)
    shutil.move(local_audio_file, dest_path)
    return final_name

def save_to_obsidian(url, title, data, original, translated, lang, audio_name):
    print("\næ­£åœ¨å†™å…¥ Obsidian...")
    md_filename = f"{OBSIDIAN_VAULT_PATH}/{title}.md"
    os.makedirs(os.path.dirname(md_filename), exist_ok=True)

    # 1. æ ‡ç­¾
    tags_yaml = "\n".join([f"  - {t}" for t in data.get("tags", [])])

    # 2. è§‚ç‚¹åˆ—è¡¨
    points_md = "\n".join([f"- {p}" for p in data.get("key_points", [])])

    # 3. æ™ºèƒ½è¯„ä¼°æ¿å—
    assess = data.get("assessment", {})
    assessment_md = f"""
### æ™ºèƒ½è¯„ä¼°
| ç»´åº¦ | è¯„ä¼°å†…å®¹ |
| :--- | :--- |
| **çœŸå®æ€§** | {assess.get('authenticity', 'N/A')} |
| **æœ‰æ•ˆæ€§** | {assess.get('effectiveness', 'N/A')} |
| **å®æ—¶æ€§** | {assess.get('timeliness', 'N/A')} |
| **æ›¿ä»£ç­–ç•¥** | {assess.get('alternatives', 'N/A')} |
"""

    # 4. ç¿»è¯‘æ¿å—
    trans_section = f"## å…¨æ–‡ç¿»è¯‘\n\n{translated}\n\n---\n" if lang != 'zh' else ""

    content = f"""---
created: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M")}
source: "{url}"
type: auto_clipper
language: {lang}
tags:
{tags_yaml}
---

# {title}

## æ™ºèƒ½æ‘˜è¦

{data.get("summary", "")}

### æ ¸å¿ƒè§‚ç‚¹

{points_md}

{assessment_md}

---

## éŸ³é¢‘å›æ”¾

![[{ASSETS_FOLDER_NAME}/{audio_name}]]

---
{trans_section}
## åŸå§‹å†…å®¹

{original}
"""
    with open(md_filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"å®Œæˆï¼ç¬”è®°å·²åˆ›å»º: {md_filename}")

def main():
    print("=== Auto-Clipper V5.0 (åŒæ¨¡å‹æ™ºèƒ½ç‰ˆ) ===")
    url = input("\nè¯·è¾“å…¥é“¾æ¥: ").strip()
    if not url: return

    title = get_video_info(url)
    if check_is_duplicate(title): return

    temp_name = f"temp_{datetime.datetime.now().strftime('%H%M%S')}"
    dl_file = download_audio(url, temp_name)
    if not dl_file: return

    try:
        whisper_res = transcribe_audio(dl_file)
        full_text = whisper_res['text']
        lang = whisper_res.get('language', 'en')

        # æ ¸å¿ƒé€»è¾‘
        formatted_orig = format_original_text(whisper_res)

        # æ­¥éª¤ 1: ä½¿ç”¨ã€åˆ†ææ¨¡å‹ã€‘åšæ·±åº¦æ€è€ƒ
        analysis_data = generate_intelligence_analysis(full_text)

        # æ­¥éª¤ 2: ä½¿ç”¨ã€ç¿»è¯‘æ¨¡å‹ã€‘åšé•¿æ–‡æœ¬ç¿»è¯‘ (å¦‚æœéœ€è¦)
        translated = ""
        if lang != 'zh':
            translated = translate_full_text_loop(full_text)

        audio_final = move_audio_to_vault(dl_file, title)
        save_to_obsidian(url, title, analysis_data, formatted_orig, translated, lang, audio_final)

    except Exception as e:
        print(f"é”™è¯¯: {e}")
    finally:
        if os.path.exists(dl_file): os.remove(dl_file)

if __name__ == "__main__":
    main()
